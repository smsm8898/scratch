{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a3eacf5-0fe2-4ea4-9dd5-881e602a0cb2",
   "metadata": {},
   "source": [
    "# 3가지 주요 Tokenizer 직접 구현\n",
    "1. BPE(Byte-Pair Encoding)\n",
    "2. WordPiece\n",
    "3. Unigram (SentencePiece 스타일)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd21815-05a3-4698-97b2-1f8c830f3e96",
   "metadata": {},
   "source": [
    "\n",
    "| 모델            | 특징                      | 한국어에서 경향               |\n",
    "| ------------- | ----------------------- | ---------------------- |\n",
    "| **BPE**       | 가장 자주 나오는 문자쌍 병합        | 적당한 길이의 subword        |\n",
    "| **WordPiece** | likelihood가 가장 높은 분해 선택 | ##붙은 subword 많음        |\n",
    "| **Unigram**   | 전체 단어를 확률적으로 선택         | 가장 자연스러운 분절이 나오는 경우 많음 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15e8dfb0-530d-46f5-91af-ebbea1778fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE, WordPiece, Unigram\n",
    "from tokenizers.trainers import BpeTrainer, WordPieceTrainer, UnigramTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b932a216-109e-4b43-a4df-bbd0f9a17457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tokenizer(corpus, model, vocab_size=50):\n",
    "    if model == \"bpe\":\n",
    "        tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "        trainer = BpeTrainer(vocab_size=vocab_size, special_tokens=[\"[UNK]\"])\n",
    "    elif model == \"wordpiece\":\n",
    "        tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))\n",
    "        trainer = WordPieceTrainer(vocab_size=vocab_size, special_tokens=[\"[UNK]\"])\n",
    "    elif model == \"unigram\":\n",
    "        tokenizer = Tokenizer(Unigram())\n",
    "        trainer = UnigramTrainer(vocab_size=vocab_size, unk_token=\"[UNK]\", special_tokens=[\"[UNK]\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model:{model}\")\n",
    "        \n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    tokenizer.train_from_iterator(corpus, trainer)\n",
    "    return tokenizer\n",
    "\n",
    "def test_sentence(sentence):\n",
    "    print(\"===== BPE =====\")\n",
    "    enc = bpe_tokenizer.encode(sentence)\n",
    "    print(f\"Tokens:{enc.tokens}\")\n",
    "    print(f\"Tokens:{enc.ids}\")\n",
    "    \n",
    "    print(\"\\n===== WordPiece =====\")\n",
    "    enc = wordpiece_tokenizer.encode(sentence)\n",
    "    print(f\"Tokens:{enc.tokens}\")\n",
    "    print(f\"Tokens:{enc.ids}\")\n",
    "    \n",
    "    print(\"\\n===== Unigram =====\")\n",
    "    enc = unigram_tokenizer.encode(sentence)\n",
    "    print(f\"Tokens:{enc.tokens}\")\n",
    "    print(f\"Tokens:{enc.ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbb5e153-acd5-4b3a-addb-1c23854dc3b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"나는 밥을 먹었다\",\n",
    "    \"나는 밥을 먹고 학교에 갔다\",\n",
    "    \"학교에서 친구를 만났다\"\n",
    "]\n",
    "\n",
    "bpe_tokenizer = train_tokenizer(corpus, \"bpe\")\n",
    "wordpiece_tokenizer = train_tokenizer(corpus, \"wordpiece\")\n",
    "unigram_tokenizer = train_tokenizer(corpus, \"unigram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b151ba91-9884-4fca-be0a-f41359f826b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== BPE =====\n",
      "Tokens:['나는', '친', '구', '[UNK]', '학교에서', '밥을', '먹었다']\n",
      "Tokens:[20, 17, 4, 0, 30, 21, 31]\n",
      "\n",
      "===== WordPiece =====\n",
      "Tokens:['나는', '[UNK]', '학교에서', '밥을', '먹었다']\n",
      "Tokens:[30, 0, 39, 31, 41]\n",
      "\n",
      "===== Unigram =====\n",
      "Tokens:['나', '는', '친', '구', '와', '학교에', '서', '밥', '을', '먹', '었', '다']\n",
      "Tokens:[6, 4, 14, 18, 0, 7, 19, 5, 2, 3, 16, 1]\n"
     ]
    }
   ],
   "source": [
    "test_sentence(\"나는 친구와 학교에서 밥을 먹었다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcff7ea5-5e2f-47ac-b311-03a14c9f1fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== BPE =====\n",
      "Tokens:['밥을', '학', '교', '[UNK]', '[UNK]', '에', '서', '먹었다']\n",
      "Tokens:[21, 18, 3, 0, 0, 15, 13, 31]\n",
      "\n",
      "===== WordPiece =====\n",
      "Tokens:['밥을', '학교', '[UNK]', '먹었다']\n",
      "Tokens:[31, 32, 0, 41]\n",
      "\n",
      "===== Unigram =====\n",
      "Tokens:['밥', '을', '학', '교', '가게', '에', '서', '먹', '었', '다']\n",
      "Tokens:[5, 2, 8, 10, 0, 9, 19, 3, 16, 1]\n"
     ]
    }
   ],
   "source": [
    "test_sentence(\"밥을 학교 가게에서 먹었다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf17141-81f8-42fb-b079-90f75250f0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767159e1-6dbd-4919-a82d-97499ed5142e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab1eb5-5e74-4cad-a7e8-fb300b33d2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500e1ca-ad6b-4ea0-b4f8-829bc63ca24d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
