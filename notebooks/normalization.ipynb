{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed6eee8b-f77c-4c4a-9983-85662acc1b9c",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "- 정의 학습을 안정화하고 gradient 폭주 or 소실을 줄이고, 수렴 속도를 빠르게 하는 기법\n",
    "- 정의, 효과, 장점, 단점, 사용 논문 예시, 시뮬레이션"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc0f64-f511-4505-a3df-ec4376a35b9e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee73016-cd67-405f-bfdd-21e4957503c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc604e-8705-44f4-bcc2-908c16a26def",
   "metadata": {},
   "source": [
    "## 1. Batch Normalization(BatchNorm)\n",
    "#### 1-1. 정의\n",
    "- 등장 배경(gradient flow 문제)\n",
    "  - 딥러닝에서 **gradient가 사라지거나 폭주**하는 문제\n",
    "  - 딥러닝 모델이 학습할 때, 레이어 입력 값의 분포가 계속 변하는 문제(Internal Covariate Shift)를 줄여주는 정규화 기법\n",
    "- 입력(mini batch) x를 평균 0, 분산 1로 정규화(각 feature의 scale을 일정하게 유지)\n",
    "  - $\\hat{x}_i=\\frac{x_i-\\mu_B}{\\sqrt{\\sigma^2_B + \\epsilon}}, \\quad y_i = \\gamma\\hat{x}_i+\\beta$\n",
    "  - $x_i$: 미니배치 입력\n",
    "  - $\\mu_B, \\sigma^2_B$: 미니배치 평균과 분산\n",
    "  - $\\gamma, \\beta$: 학습 가능한 scale & shift 파라미터\n",
    "  - $\\epsilon$: 안정화를 위한 작은 값\n",
    "\n",
    "#### 1-2. 장점\n",
    "- 학습 안정화: gradient exploding/vanishing 위험이 크게 감소\n",
    "- 학습 속도 향상\n",
    "  - 더 큰 lr 사용 가능\n",
    "  - SGD가 훨씬 잘 작동\n",
    "- 성능 향상: CNN, MLP에서 성능 향상 명확\n",
    "- 일종의 regularization 효과\n",
    "  - 각 배치마다 mean, var이 달라서 dropout 효과와 비슷\n",
    "  - 과적합 방지\n",
    "  \n",
    "#### 1-3. 단점\n",
    "- 배치 크기에 민감\n",
    "  - Batch size가 작으면 mean, var이 불안정해짐\n",
    "- 시퀀스 길이가 변하거나 온라인 학습에서는 부적합\n",
    "  - RNN, Transformer 배치 단위 통계(Mean, Var)가 불안정하고 sequence length등 다름\n",
    "  - LayerNorm\n",
    "- 추론 때는 moving average 통계를 사용해야 해서 설정이 까다로움\n",
    "- GPU 병렬성 제약\n",
    "  - 분산 학습 시 각 GPU마다 batch 통계가 달라지는 문제\n",
    "  - SyncBatchNorm 필요\n",
    "  \n",
    "#### 1-4. 사용예시\n",
    "- 이미지 처리(CNN): ResNet, VGG, EfficientNet\n",
    "- 대규모 FC 네트워크(MLP)\n",
    "- GAN 일부\n",
    "\n",
    "#### 1-5. 용어설명\n",
    "- Covariate\n",
    "  - 통계학에서 \"변수들 간의 관계를 설명하는 독립 변수\"\n",
    "  - 쉽게 말하면 관찰된는 입력 변수\n",
    "    - 예1. 키와 몸무게 관계를 연구한다면, 키가 covariate, 몸무게가 결과(y)\n",
    "    - 예2. 딥러닝에서는 layer로 들어오는 입력 x가 covariate\n",
    "- Internal Covariate\n",
    "  - 네트워크 내부의 covariate\n",
    "  - 즉, 각 layer로 들어가는 입력(feature) 자체가 학습 과정에서 계속 변하는 것\n",
    "- 문제 상황\n",
    "  - Layer1 → Layer2 → Layer3 순으로 학습할 때, Layer1이 학습되면서 출력이 조금씩 바뀌면\n",
    "  - Layer2 입력 분포도 계속 변함 → graident 학습에 방해\n",
    "  - 즉, 네트워크 내부 feature의 분포가 학습 도중에 계속 이동하는 현상\n",
    "    - BatchNorm은 layer1의 output(z1)을 평균 0, 분산 1로 정규화 \n",
    "    - layer2가 일정한 분포의 입력을 받아 안정적인 gradient flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d75f9000-c12c-4687-a499-8182f11f8eb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | DIFF: -0.1921 | No BN Loss: 1.1506 | BN Loss: 1.3427\n",
      "Epoch 20 | DIFF: -0.0114 | No BN Loss: 1.1243 | BN Loss: 1.1357\n",
      "Epoch 30 | DIFF: 0.1117 | No BN Loss: 1.0990 | BN Loss: 0.9873\n",
      "Epoch 40 | DIFF: 0.1983 | No BN Loss: 1.0747 | BN Loss: 0.8764\n",
      "Epoch 50 | DIFF: 0.2613 | No BN Loss: 1.0513 | BN Loss: 0.7900\n",
      "Epoch 60 | DIFF: 0.3088 | No BN Loss: 1.0286 | BN Loss: 0.7199\n",
      "Epoch 70 | DIFF: 0.3456 | No BN Loss: 1.0067 | BN Loss: 0.6611\n",
      "Epoch 80 | DIFF: 0.3748 | No BN Loss: 0.9854 | BN Loss: 0.6106\n",
      "Epoch 90 | DIFF: 0.3985 | No BN Loss: 0.9647 | BN Loss: 0.5662\n",
      "Epoch 100 | DIFF: 0.4180 | No BN Loss: 0.9446 | BN Loss: 0.5266\n",
      "MEAN:tensor([ 0.0635,  0.1785, -0.0881,  0.0043, -0.0157, -0.3289,  0.2877,  0.0256,\n",
      "         0.0033, -0.1295,  0.1910,  0.2438,  0.1987, -0.0557,  0.1170, -0.2819,\n",
      "        -0.2182, -0.2477,  0.2318,  0.1992,  0.2348, -0.1188,  0.0194,  0.2432,\n",
      "         0.1643, -0.1981,  0.1550,  0.0160,  0.0167,  0.0288,  0.2727, -0.0576,\n",
      "        -0.0360,  0.0059,  0.2292, -0.2853,  0.1873, -0.2150,  0.0247,  0.1208,\n",
      "         0.2344, -0.1534, -0.1009, -0.2777, -0.2530, -0.2645,  0.2030,  0.1584,\n",
      "         0.0993, -0.2444,  0.0072, -0.1304, -0.2070,  0.0361, -0.1210,  0.3043,\n",
      "        -0.3178,  0.1839,  0.1982,  0.1868, -0.2527, -0.2661, -0.0319,  0.1033])\n",
      "VAR:tensor([0.2328, 0.3072, 0.2332, 0.2895, 0.1854, 0.3027, 0.3684, 0.2306, 0.2489,\n",
      "        0.3526, 0.5189, 0.2896, 0.1972, 0.4066, 0.3143, 0.4205, 0.4818, 0.2181,\n",
      "        0.3263, 0.3294, 0.3889, 0.2083, 0.3813, 0.5531, 0.4480, 0.2919, 0.3383,\n",
      "        0.3751, 0.4554, 0.6428, 0.2939, 0.3128, 0.4271, 0.1478, 0.3282, 0.3557,\n",
      "        0.1887, 0.4453, 0.3965, 0.4512, 0.4351, 0.3119, 0.4581, 0.3196, 0.3311,\n",
      "        0.3436, 0.2730, 0.3901, 0.3347, 0.3140, 0.3221, 0.1482, 0.3877, 0.1786,\n",
      "        0.4005, 0.3256, 0.3358, 0.4065, 0.3873, 0.4352, 0.3320, 0.4030, 0.2120,\n",
      "        0.4767])\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, batchnorm=False):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64) if batchnorm else nn.Identity()\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "# Dataset: y = 3x + noise\n",
    "x = torch.randn(1000, 10)\n",
    "y = x[:, 0] + torch.randn(1000) * 0.1\n",
    "y = y.unsqueeze(1)\n",
    "\n",
    "# Simple Comparison\n",
    "no_bn_model = MLP(False)\n",
    "no_bn_optimizer = torch.optim.SGD(no_bn_model.parameters(), lr=1e-3)\n",
    "\n",
    "bn_model = MLP(True)\n",
    "bn_optimizer = torch.optim.SGD(bn_model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "for epoch in range(100):\n",
    "    # no bn\n",
    "    no_bn_optimizer.zero_grad()\n",
    "    no_bn_pred = no_bn_model(x)\n",
    "    no_bn_loss = criterion(no_bn_pred, y)\n",
    "    no_bn_loss.backward()\n",
    "    no_bn_optimizer.step()\n",
    "    \n",
    "    # bn\n",
    "    bn_optimizer.zero_grad()\n",
    "    bn_pred = bn_model(x)\n",
    "    bn_loss = criterion(bn_pred, y)\n",
    "    bn_loss.backward()\n",
    "    bn_optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1} | DIFF: {no_bn_loss.item() - bn_loss.item():.4f} | No BN Loss: {no_bn_loss.item():.4f} | BN Loss: {bn_loss.item():.4f}\")\n",
    "        \n",
    "\n",
    "print(f\"MEAN:{bn_model.bn1.running_mean}\")\n",
    "print(f\"VAR:{bn_model.bn1.running_var}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26326f0f-e53e-4fc8-9f2b-9169c6e4fe03",
   "metadata": {},
   "source": [
    "## 2. Layer Normalization(LayerNorm)\n",
    "#### 2-1. 정의\n",
    "- 등장 배경(gradient flow 문제)\n",
    "  - 딥러닝에서 **gradient가 사라지거나 폭주**하는 문제\n",
    "  - 특히 **RNN, Transformer** 같은 Sequence 모델에서는 BatchNorm 적용이 어려움\n",
    "    - 미니배치 통계(Mean, Var)가 Sequence 길이에 따라 달라지거나 batch size가 작은 경우가 많음\n",
    "- **LayerNorm**은 배치 단위가 아니라 feature 단위로 정규화\n",
    "  - 즉, 한 sample 내 모든 feature를 평균 0, 분산 1로 변환\n",
    "  - $\\hat{x}_i=\\frac{x_i-\\mu_L}{\\sqrt{\\sigma^2_L + \\epsilon}}, \\quad y_i = \\gamma\\hat{x}_i+\\beta$\n",
    "  - $x_i$: 한 샘플의 feature\n",
    "  - $\\mu_L, \\sigma^2_L$: 한 샘플의 평균과 분산\n",
    "  - $\\gamma, \\beta$: 학습 가능한 scale & shift 파라미터\n",
    "  - $\\epsilon$: 안정화를 위한 작은 값\n",
    "    - **차이점**: BatchNorm은 batch dimension, LayerNorm은 feature dimension\n",
    "    - batchnorm은 sample 내 feature가 독립적일 때 (sex, age, country, ...) \n",
    "    - layernorm은 sample 내 feature가 의존적일 때 sentence\n",
    "\n",
    "#### 2-2. 장점\n",
    "- **배치 크기 독립적: batch size가 1이어도 안정적**\n",
    "- Sequence 모델에 적합(RNN, Transformer)\n",
    "- Gradient 안정화: 한 샘플 내 feature 분포를 일정하게 유지(gradient exploding/vanishing 감소)\n",
    "- 학습 속도 향상: 안정적인 gradient flow 덕분에 학습이 빠르고 수렴이 잘 됨\n",
    "  \n",
    "#### 2-3. 단점\n",
    "- **공간 정보 손실 가능**: CNN에서 feature map 정규화 시 spatial 정보를 무시\n",
    "- BatchNorm 대비 약간 느린 학습: batch 단위 정규화가 병렬 처리에 더 효율적\n",
    "- 일부 연구에서는 regularization 효과가 BatchNorm보다 약함\n",
    "  \n",
    "#### 2-4. 사용예시\n",
    "- Sequence Modeling: RNN, LSTM, GRU\n",
    "- Attention: Transformer, BERT, GPT, ViT 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cd4b50c-c99e-4a73-9907-a15c817fa090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | DIFF: -0.1564 | No LN Loss: 0.9443 | LN Loss: 1.1007\n",
      "Epoch 20 | DIFF: -0.1073 | No LN Loss: 0.9206 | LN Loss: 1.0279\n",
      "Epoch 30 | DIFF: -0.0667 | No LN Loss: 0.8978 | LN Loss: 0.9645\n",
      "Epoch 40 | DIFF: -0.0322 | No LN Loss: 0.8757 | LN Loss: 0.9079\n",
      "Epoch 50 | DIFF: -0.0021 | No LN Loss: 0.8543 | LN Loss: 0.8563\n",
      "Epoch 60 | DIFF: 0.0246 | No LN Loss: 0.8335 | LN Loss: 0.8089\n",
      "Epoch 70 | DIFF: 0.0484 | No LN Loss: 0.8133 | LN Loss: 0.7649\n",
      "Epoch 80 | DIFF: 0.0698 | No LN Loss: 0.7937 | LN Loss: 0.7239\n",
      "Epoch 90 | DIFF: 0.0890 | No LN Loss: 0.7746 | LN Loss: 0.6856\n",
      "Epoch 100 | DIFF: 0.1064 | No LN Loss: 0.7561 | LN Loss: 0.6497\n",
      "WEIGHT:Parameter containing:\n",
      "tensor([1.0040, 1.0032, 1.0005, 0.9999, 1.0000, 0.9975, 0.9996, 1.0005, 0.9974,\n",
      "        0.9992, 1.0003, 0.9981, 0.9994, 1.0030, 0.9994, 1.0025, 0.9978, 0.9995,\n",
      "        0.9991, 0.9965, 1.0007, 1.0004, 1.0024, 0.9992, 1.0008, 1.0002, 0.9993,\n",
      "        0.9999, 0.9997, 0.9992, 0.9999, 1.0012, 0.9988, 1.0010, 0.9967, 1.0026,\n",
      "        0.9999, 0.9983, 0.9988, 0.9979, 0.9989, 1.0000, 1.0019, 1.0012, 1.0027,\n",
      "        0.9977, 0.9997, 0.9973, 0.9977, 1.0002, 1.0000, 1.0020, 0.9985, 1.0004,\n",
      "        1.0006, 1.0007, 1.0034, 1.0024, 0.9981, 1.0026, 0.9994, 0.9967, 1.0005,\n",
      "        1.0014], requires_grad=True)\n",
      "BIAS:Parameter containing:\n",
      "tensor([ 3.6340e-03,  3.2508e-03,  4.4503e-04,  1.7533e-04,  4.8532e-05,\n",
      "        -1.5313e-03, -2.4807e-04,  5.9793e-04, -2.7081e-03, -7.7876e-04,\n",
      "         3.4586e-04, -1.6845e-03, -5.8628e-04,  2.0183e-03, -3.2027e-04,\n",
      "         1.6051e-03, -2.5290e-03, -6.1639e-05, -8.7152e-04, -2.3264e-03,\n",
      "         5.2011e-04,  5.9079e-04,  1.0850e-03, -1.0530e-03,  6.2484e-04,\n",
      "        -6.0762e-05, -7.7112e-04, -1.3421e-04, -1.8243e-06, -7.3915e-04,\n",
      "        -5.5819e-05,  9.0599e-04, -1.1588e-03,  1.0198e-03, -2.3336e-03,\n",
      "         2.6547e-03, -1.1407e-04, -9.1818e-04, -1.2539e-03, -1.6001e-03,\n",
      "        -1.8931e-03, -5.4231e-05,  2.2758e-03,  9.2513e-04,  1.2386e-03,\n",
      "        -1.6588e-03, -4.9040e-04, -2.0559e-03, -2.7646e-03,  2.8111e-04,\n",
      "        -1.2248e-05,  1.6398e-03, -1.5736e-03,  2.7885e-04,  8.9885e-04,\n",
      "         9.7928e-04,  4.2539e-03,  2.1383e-03, -1.3933e-03,  2.6057e-03,\n",
      "        -4.1730e-04, -2.3792e-03,  1.1411e-04,  1.1078e-03],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, layernorm=False):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 64)\n",
    "        self.ln1 = nn.LayerNorm(64) if layernorm else nn.Identity()\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.ln1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "# Dataset: y = 3x + noise\n",
    "x = torch.randn(1000, 10)\n",
    "y = x[:, 0] + torch.randn(1000) * 0.1\n",
    "y = y.unsqueeze(1)\n",
    "\n",
    "# Simple Comparison\n",
    "no_ln_model = MLP(False)\n",
    "no_ln_optimizer = torch.optim.SGD(no_ln_model.parameters(), lr=1e-3)\n",
    "\n",
    "ln_model = MLP(True)\n",
    "ln_optimizer = torch.optim.SGD(ln_model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "for epoch in range(100):\n",
    "    # no bn\n",
    "    no_ln_optimizer.zero_grad()\n",
    "    no_ln_pred = no_ln_model(x)\n",
    "    no_ln_loss = criterion(no_ln_pred, y)\n",
    "    no_ln_loss.backward()\n",
    "    no_ln_optimizer.step()\n",
    "    \n",
    "    # bn\n",
    "    ln_optimizer.zero_grad()\n",
    "    ln_pred = ln_model(x)\n",
    "    ln_loss = criterion(ln_pred, y)\n",
    "    ln_loss.backward()\n",
    "    ln_optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1} | DIFF: {no_ln_loss.item() - ln_loss.item():.4f} | No LN Loss: {no_ln_loss.item():.4f} | LN Loss: {ln_loss.item():.4f}\")\n",
    "\n",
    "print(f\"WEIGHT:{ln_model.ln1.weight}\")\n",
    "print(f\"BIAS:{ln_model.ln1.bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f5abc-2985-4136-be65-cb6dab889990",
   "metadata": {},
   "source": [
    "## 3. Instance Normalization(InstanceNorm)\n",
    "#### 3-1. 정의\n",
    "- 등장 배경(gradient flow 문제)\n",
    "  - **Style Transfer, Image Generation** 에서 등장\n",
    "  - CNN feature map마다 **style(밝기, 대비 등) 차이**가 심할 때, gradient flow 안정화 필요\n",
    "- **InstanceNorm**은 배치 단위가 아니라 각 샘플의 각 채널(feature map)별로 정규화\n",
    "  - 즉, batch-independent, channel-wise normalization\n",
    "  - $\\hat{x}_{n, c, h, w}=\\frac{x_{n, c, h, w}-\\mu_{n, c}}{\\sqrt{\\sigma^2_{n, c} + \\epsilon}}, \\quad y_{n, c, h, w} = \\gamma\\hat{x}_{n, c, h, w}+\\beta_c$\n",
    "  - $n$: 배치 index\n",
    "  - $c$: channel\n",
    "  - $\\mu_{n,c}, \\sigma^2_{n,c}:$: 한 샘플의 한 채널에 대한 평균/분산\n",
    "  - $\\gamma_c, \\beta_c$: 채널별 학습 가능한 scale & shift 파라미터\n",
    "    \n",
    "#### 3-2. 장점\n",
    "- **스타일/조명 불변성 확보**\n",
    "  - style transfer에서 style에 관계없이 content를 잘 학습 가능\n",
    "- 배치 크기 독립적(batch size가 1이어도 안정적 학습 가능)\n",
    "- Gradient 안정화: CNN feature map이 지나면서 gradient exploding/vanishing 감소\n",
    "  \n",
    "#### 3-3. 단점\n",
    "- BatchNorm 대비 일반화 효과 낮음(regularization 효과 없음)\n",
    "- 내용과 style분리가 필요 없는 일반 학습에는 효과 없음\n",
    "  - 시퀀스 모델에는 적합하지 않음\n",
    "  \n",
    "#### 3-4. 사용예시\n",
    "- Image Style Transfer: AdaIN(Adative InstanceNorm) 등\n",
    "- CNN 기반 이미지 생성 모델\n",
    "- GANs: CycleGAN, StyleGAN 등\n",
    "\n",
    "\n",
    "#### 3-5. 적용 예시\n",
    "- x: (4, 3, 32, 32)\n",
    "- self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "- self.in1 = nn.InstanceNorm2d(16)\n",
    "  \n",
    "```\n",
    "Input: (4, 3, 32, 32)  -> Conv2d -> (4, 16, 32, 32)\n",
    "                   -> InstanceNorm2d:\n",
    "                      batch 0, channel 0 -> 평균 0, 분산 1\n",
    "                      batch 0, channel 1 -> 평균 0, 분산 1\n",
    "                      ...\n",
    "                      batch 3, channel 15 -> 평균 0, 분산 1\n",
    "Output: (4, 16, 32, 32) 정규화된 feature map\n",
    "```\n",
    "\n",
    "- 배치끼리 통계 공유하지 않음(batch size 1도 안정적)\n",
    "- 채널 단위로 정규화(스타일 제거, content 정보 보존)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7266d-ace8-42f3-baa9-30083425d58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c7d4472-3cb5-496b-b867-c6910dce37ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, instancenorm=False):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.in1 = nn.InstanceNorm2d(16) if instancenorm else nn.Identity()\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.in1(x)\n",
    "        # 각 샘플별, 각 채널별 평균과 분산 계산\n",
    "        # batch[0], channel[0] > 32x32 값의 평균0_0, 분산0_0\n",
    "        # batch[0], channel[1] > 32x32 값의 평균0_1, 분산0_1\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "# Dummy input: batch 4, RGB image 32x32\n",
    "x = torch.randn(4, 3, 32, 32)\n",
    "\n",
    "model = CNN(instancenorm=True)\n",
    "out = model(x)\n",
    "print(out.shape)  # (4, 32, 32, 32)\n",
    "\n",
    "for p in model.in1.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7558692e-4386-4be3-8ac9-a9367646c03c",
   "metadata": {},
   "source": [
    "## 4. Group Normalization(GroupNorm)\n",
    "#### 4-1. 정의\n",
    "- 등장 배경\n",
    "  - BatchNorm의 단점: 작은 Batch Sized에서 불안정\n",
    "  - BatchNorm 없이도 gradient flow 안정화 가능하도록 고안\n",
    "- 핵심 아이디어\n",
    "  - 채널을 여러 그룹으로 나누고, 각 그룹 내에서 정규화\n",
    "  - 즉, BatchNorm과 InstanceNorm의 중간 형태\n",
    "  - $\\hat{x}_{n, g}=\\frac{x_{n, g}-\\mu_{n,g}}{\\sqrt{\\sigma^2_{n,g} + \\epsilon}}, \\quad y_{n, g} = \\gamma_g\\hat{x}_{n,g}+\\beta_g$\n",
    "  - $n$: 샘플 인덱스\n",
    "  - $g$: 그룹 인덱스(각 그룹 내 채널 정규화)\n",
    "  - $\\mu_{n,g}, \\sigma^2_{n, g}$: 그룹 내 평균, 분산\n",
    "  - $\\gamma_g, \\beta_g$: 학습 가능한 scale & shift 파라미터\n",
    "  - $\\epsilon$: 안정화를 위한 작은 값\n",
    "    - 특징:\n",
    "    - InstanceNorm = 채널 1개씩 그룹화\n",
    "    - LayerNorm = 전체 채널을 1개의 그룹\n",
    "\n",
    "#### 4-2. 장점\n",
    "- **배치 크기 독립적: batch size가 1이어도 안정적**\n",
    "- Gradient 안정화: gradient exploding/vanishing 감소\n",
    "- CNN에서 공간 정보 보존 가능\n",
    "- BatchNorm보다 작은 배치, GPU memory 제약 환경에 강함\n",
    "  \n",
    "#### 4-3. 단점\n",
    "- 채널 그룹 수 하이퍼파라미터 필요\n",
    "  - 그룹 개수(G)가 너무 크거나 작으면 성능에 영향\n",
    "- BatchNorm의 regularization 효과는 일부 감소\n",
    "  \n",
    "#### 4-4. 사용예시\n",
    "- Small-batch CNN: object detection, segmentation 등\n",
    "- ResNeXT, Detectron2 일부 모듈\n",
    "- BatchNorm 적용이 어려움 medical image segmentation에서도 사용\n",
    "\n",
    "#### 4-5. gradient flow 관점\n",
    "- 그룹 단위 정규화 → channel correlation 유지하면서도 gradient 안정화\n",
    "- BatchNorm처럼 batch 통계 의존 X → 작은 batch size에서도 학습 안정적\n",
    "- InstanceNorm처럼 style 제거보다는 content 정보 보존\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28d3d513-6cb8-44b2-80f9-55350ddc932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, groupnorm=False, G=4):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.gn1 = nn.GroupNorm(num_groups=G, num_channels=16) if groupnorm else nn.Identity()\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.gn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "# Dummy input: batch 4, RGB 32x32\n",
    "x = torch.randn(4, 3, 32, 32)\n",
    "model = CNN(groupnorm=True, G=4)\n",
    "out = model(x)\n",
    "print(out.shape)  # (4, 32, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e0cf682-669f-4b27-a4d0-51cc07db7ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.gn1.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae990d45-bceb-4212-b7d0-ebc31c074584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e1b01-fa43-4022-a383-1aea6c7d57b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c80e24c-8dcc-4819-8e01-d63bd956a74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b24c1d92-69f9-4d76-aa51-085268ffa05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pred(logits): (batch_size, num_classes)\n",
    "            target(class indices): (batch_size)\n",
    "        \"\"\"\n",
    "\n",
    "        num_classes = pred.size(1)\n",
    "        # one-hot vector\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred) # (batch_size, num_classes)\n",
    "            # 0보다 조금 큰 값\n",
    "            true_dist.fill_(self.smoothing / (num_classes - 1)) \n",
    "            # true_dist에 target index 부분의 값을 1-Smoothing으로 체우는 함수\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), 1.0 - self.smoothing)\n",
    "\n",
    "        log_prob = F.log_softmax(pred, dim=1)\n",
    "        loss = torch.mean(torch.sum(-true_dist * log_prob, dim=1))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c8dbfd1-69a5-49dd-81cc-3a62f51d6b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss:5.0733\n",
      "Label Smooth Cross Entropy Loss:5.0756\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "num_classes = 100\n",
    "\n",
    "ce = nn.CrossEntropyLoss() # 기존\n",
    "ce_smooth = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
    "\n",
    "pred = torch.randn(batch_size, num_classes, requires_grad=True)\n",
    "target = torch.randint(low=0, high=num_classes-1, size=(batch_size,))\n",
    "\n",
    "ce_loss = ce(pred, target)\n",
    "ce_smooth_loss = ce_smooth(pred, target)\n",
    "\n",
    "\n",
    "print(f\"Cross Entropy Loss:{round(ce_loss.item(), 4)}\")\n",
    "print(f\"Label Smooth Cross Entropy Loss:{round(ce_smooth_loss.item(), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180ceca7-033d-40a9-ab05-f49c79e5139e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6fb908-883b-4bc6-a78b-c324571eeec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61cf29b-d027-4001-8ef1-e54a4adc41de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9daae5-f23f-4281-956e-1d22efd0377a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ba547-1703-4026-b4ad-65607ce9081d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
